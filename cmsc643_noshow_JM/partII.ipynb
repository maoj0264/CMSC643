{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Model Building\n",
    "\n",
    "Here you try your hand at model building to predict appointment no shows.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Package 'noshow_lib' now includes code to carry out preprocessing steps from part I. Here's how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noshow_lib.util as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it includes a dictionary used for configuring path and file names\n",
    "used through the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_path': 'data',\n",
       " 'raw_data_csv': 'KaggleV2-May-2016.csv',\n",
       " 'processed_data_path': 'processed_data',\n",
       " 'train_csv': 'train_set.csv',\n",
       " 'test_csv': 'test_set.csv',\n",
       " 'objstore_path': 'objects',\n",
       " 'feature_pipeline_file': 'feature_pipeline.pkl',\n",
       " 'labels_pipeline_file': 'labels_pipeline.pkl'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.file_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`feature_pipeline_file`: file storing the preprocessing pipeline used for preparing the feature matrix\n",
    "\n",
    "`labels_pipeline_file`: file storing the preprocessing pipeline used for\n",
    "preparing labels\n",
    "\n",
    "`objstore_path`: directory to store python objects to disk\n",
    "\n",
    "`processed_data_path`: directory containing processed data\n",
    "\n",
    "`raw_data_csv`: name of the csv download from Kaggle\n",
    "\n",
    "`raw_data_path`: directory containing raw data\n",
    "\n",
    "`test_csv`: name of csv file containing test set\n",
    "\n",
    "`train_csv`: name of csv file containing train set\n",
    "\n",
    "You can change these paths and names to suit your project directory structure if you need so. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_config = utils.file_config\n",
    "#config['raw_data_path'] = \"some_other_directory\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to create train test sets. Code is in file `noshow_lib/util.py` function `make_train_test_sets`. You\n",
    "can edit that function as needed to include your own part I code if you so desire. The result will be to \n",
    "create files `train_set.csv` and `test_set.csv` in your `processed_data` directory (unless you change any of the entries in the configuration directory as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY NEED TO RUN THIS STEP ONCE (switch this to True to run it)\n",
    "RUN_MAKE_TRAIN_TEST_FILES = False\n",
    "if RUN_MAKE_TRAIN_TEST_FILES:\n",
    "    utils.make_train_test_sets(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to fit the preprocessing pipelines. This is done in file `noshow_lib/preprocess.py`. Again you can edit code as needed in that file to incorporate your part I solution as you wish. The result will be to create files `feature_pipeline.pkl` and `labels_pipeline.pkl` containing the fit preprocessing pipelines we can then use to preprocess data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noshow_lib.preprocess as preprocess\n",
    "\n",
    "# ONLY NEED TO RUN THIS STEP ONCE\n",
    "RUN_FIT_PREPROCESSING = False\n",
    "if RUN_FIT_PREPROCESSING:\n",
    "    preprocess.fit_save_pipelines(config=file_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we do that, we can get a training matrix and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = preprocess.load_train_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90526"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90526, 113)\n",
      "(90526,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = preprocess.load_test_data(config=file_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 113)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "Using `sklearn` fit:\n",
    "    - DecisionTree classifier\n",
    "    - RandomForest classifier\n",
    "    - Linear SVM classifier\n",
    "    - SVM with Radial Basis Kernel classifier\n",
    "    \n",
    "Use default parameters for now.\n",
    "Using 10-fold cross validation report both accuracy and AUC for each of the above four models.\n",
    "\n",
    "QUESTION: Should you use accuracy or AUC for this task as a performance metric?\n",
    "\n",
    "_ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - DecisionTree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Accuracy : 0.73935\n"
     ]
    }
   ],
   "source": [
    "#Classifier imports\n",
    "from sklearn import tree\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt.fit(train_X, train_y)\n",
    "test_y_dt_model = dt.predict(test_X)\n",
    "print(\"DecisionTree Accuracy :\", accuracy_score(test_y, test_y_dt_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - RandomForest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Accuracy : 0.7771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(train_X, train_y)\n",
    "test_y_rf_model = rf.predict(test_X)\n",
    "print(\"RandomForest Accuracy :\", accuracy_score(test_y, test_y_rf_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 - Linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Accuracy : 0.7956\n"
     ]
    }
   ],
   "source": [
    "# build your models here\n",
    "# Linear SVM classifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(train_X, train_y)\n",
    "\n",
    "test_y_lsvc_model = lsvc.predict(test_X)\n",
    "print(\"LinearSVC Accuracy :\", accuracy_score(test_y, test_y_lsvc_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import model_selection\n",
    "model = LinearSVC()\n",
    "results = model_selection.cross_val_score(model, train_X, train_y, cv=10)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4 - SVM with Radial Basis Kernel classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Radial Basis Kernel Accuracy : 0.79805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "rbf = SVC(kernel='rbf')  \n",
    "rbf.fit(train_X, train_y)\n",
    "\n",
    "test_y_rbf_model = rbf.predict(test_X)\n",
    "print(\"SVM with Radial Basis Kernel Accuracy :\", accuracy_score(test_y, test_y_rbf_model))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "def show_results(model_name, pred_y):\n",
    "    print(model_name + \" Measurements:\")\n",
    "    print(confusion_matrix(test_y,pred_y))  \n",
    "    print(classification_report(test_y,pred_y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with Radial Basis Kernel Measurements:\n",
      "[[15961     0]\n",
      " [ 4039     0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      1.00      0.89     15961\n",
      "          1       0.00      0.00      0.00      4039\n",
      "\n",
      "avg / total       0.64      0.80      0.71     20000\n",
      "\n",
      "\n",
      "RandomForest Measurements:\n",
      "[[14706  1255]\n",
      " [ 3203   836]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.82      0.92      0.87     15961\n",
      "          1       0.40      0.21      0.27      4039\n",
      "\n",
      "avg / total       0.74      0.78      0.75     20000\n",
      "\n",
      "\n",
      "Linear SVM Measurements:\n",
      "[[15874    87]\n",
      " [ 4001    38]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.80      0.99      0.89     15961\n",
      "          1       0.30      0.01      0.02      4039\n",
      "\n",
      "avg / total       0.70      0.80      0.71     20000\n",
      "\n",
      "\n",
      "DecisionTree Measurements:\n",
      "[[13429  2532]\n",
      " [ 2681  1358]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.83      0.84      0.84     15961\n",
      "          1       0.35      0.34      0.34      4039\n",
      "\n",
      "avg / total       0.74      0.74      0.74     20000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "measurements =((\"SVM with Radial Basis Kernel\",test_y_rbf_model),\n",
    "    (\"RandomForest\",test_y_rf_model),\n",
    "    (\"Linear SVM\",test_y_lsvc_model),\n",
    "    (\"DecisionTree\",test_y_dt_model))\n",
    "\n",
    "for model_name, pred_y in measurements:\n",
    "    show_results(model_name,pred_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "Based on classification_report result, Random Forest has the best performance on prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning\n",
    "\n",
    "Based on the above, choose two methods and fit a tuned model:\n",
    "    - use 5-fold cross validation for model selection\n",
    "    - use 10-fold cross validation for model assessment (based on appropriate performance metric)\n",
    "\n",
    "Report estimated performance for both tuned classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Randon Forest parameters\n",
      "\n",
      "Best parameters set found on 10-fold cross validation development set:\n",
      "\n",
      "{'max_features': 'sqrt', 'n_estimators': 100}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-1e69c16c1761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Grid scores on training set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"# Tuning Randon Forest parameters\")\n",
    "print()\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1,max_features= 'sqrt' ,n_estimators=50, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100,150,200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#use 10-fold cross validation \n",
    "rf_tuner = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "rf_tuner.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameters set found on 10-fold cross validation development set:\")\n",
    "print()\n",
    "print(rf_tuner.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = rf_tuner.cv_results_['mean_test_score']\n",
    "stds = rf_tuner.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_tuner.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Randon Forest parameters\n",
      "\n",
      "Best parameters set found on 5-fold cross validation development set:\n",
      "\n",
      "{'max_features': 20, 'n_estimators': 150}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.720 (+/-0.005) for {'max_features': 20, 'n_estimators': 50}\n",
      "0.725 (+/-0.006) for {'max_features': 20, 'n_estimators': 150}\n",
      "0.721 (+/-0.007) for {'max_features': 30, 'n_estimators': 50}\n",
      "0.725 (+/-0.006) for {'max_features': 30, 'n_estimators': 150}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"# Tuning Randon Forest parameters\")\n",
    "print()\n",
    "parameters = [{'n_estimators': [50,150],\n",
    "               'max_features': [20,30]}]\n",
    "rf = RandomForestClassifier()\n",
    "rf_tuner = GridSearchCV(estimator=rf, param_grid=parameters, cv=5,scoring='roc_auc',n_jobs = 6)\n",
    "rf_tuner.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameters set found on 5-fold cross validation development set:\")\n",
    "print()\n",
    "print(rf_tuner.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = rf_tuner.cv_results_['mean_test_score']\n",
    "stds = rf_tuner.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_tuner.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Randon Forest parameters\n",
      "\n",
      "Best parameters set found on 10-fold cross validation development set:\n",
      "\n",
      "{'max_features': 20, 'n_estimators': 50}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n",
      "0.718 (+/-0.010) for {'max_features': 20, 'n_estimators': 30}\n",
      "0.722 (+/-0.012) for {'max_features': 20, 'n_estimators': 50}\n",
      "0.718 (+/-0.013) for {'max_features': 30, 'n_estimators': 30}\n",
      "0.722 (+/-0.013) for {'max_features': 30, 'n_estimators': 50}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"# Tuning Randon Forest parameters\")\n",
    "print()\n",
    "parameters = [{'n_estimators': [50,150],\n",
    "               'max_features': [20,30]}]\n",
    "rf = RandomForestClassifier()\n",
    "rf_tuner = GridSearchCV(estimator=rf, param_grid=parameters, cv=10,scoring='roc_auc',n_jobs = 6)\n",
    "rf_tuner.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameters set found on 10-fold cross validation development set:\")\n",
    "print()\n",
    "print(rf_tuner.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = rf_tuner.cv_results_['mean_test_score']\n",
    "stds = rf_tuner.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_tuner.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning Randon Forest parameters\n",
      "\n",
      "Best parameters set found on 10-fold cross validation development set:\n",
      "\n",
      "{'max_features': 30, 'n_estimators': 200}\n",
      "\n",
      "Grid scores on training set:\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e58d678667db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Grid scores on training set:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mstds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'std_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_tuner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"# Tuning Randon Forest parameters\")\n",
    "print()\n",
    "\n",
    "rfc = RandomForestClassifier(n_jobs=-1, oob_score = True) \n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [100,150,200],\n",
    "    'max_features': [30, 20]\n",
    "}\n",
    "\n",
    "#use 10-fold cross validation \n",
    "rf_tuner = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 10)\n",
    "rf_tuner.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameters set found on 10-fold cross validation development set:\")\n",
    "print()\n",
    "print(rf_tuner.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = rf_tuner.cv_results_['mean_test_score']\n",
    "stds = rf_tuner.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, rf_tuner.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#This one runs forever and eventually causes my machine dead.\n",
    "print(\"# Tuning hyper-parameters\")\n",
    "print()\n",
    "parameters = [{'kernel': ['rbf'],\n",
    "               'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5],\n",
    "                'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "clf = GridSearchCV(SVC(decision_function_shape='ovr'), parameters, cv=5)\n",
    "clf.fit(train_X, train_y)\n",
    "\n",
    "print(\"Best parameters set found on 5-fold cross validation development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on training set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initialize model parameters w and b\n",
    "# intializing to 0 is not a good idea\n",
    "# it should be a random vector see np.random.randn\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _initialize_parameters(nfeatures):\n",
    "    w_b = (np.random.randn(1, 2))/10000000\n",
    "    \n",
    "    #w = ((np.random.randn(1, nfeatures))/10000000).tolist()[0] #?? all w should be same or different?\n",
    "    \n",
    "    w = np.full((nfeatures), w_b[0][0])\n",
    "    b = np.full((1), w_b[0][1])\n",
    "    return w, b\n",
    "\n",
    "# this is a vectorized version of positive_part operation\n",
    "# we can use this for hinge loss as post_part(1.0 - y*f)\n",
    "pos_part = np.vectorize(lambda u: u if u > 0. else 0.)\n",
    "\n",
    "# compute the value of the linear SVM objective function\n",
    "# given current signed distances, and parameter vector w\n",
    "def _get_objective(f, y, w, lam):\n",
    "    nobs = y.shape[0]\n",
    "    loss = np.sum(pos_part(1.0 - y*f)) / nobs\n",
    "    penalty = 0.5 * lam * np.dot(w,w)\n",
    "    return loss + penalty\n",
    "\n",
    "# compute the signed distances\n",
    "# based on current model estimates\n",
    "# w and b\n",
    "# YOU NEED TO IMPLEMENT THIS\n",
    "def _get_signed_distances(X, w, b):   \n",
    "    result = np.full((len(X),len(w[0])), 0).tolist()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(w[0])):\n",
    "            for k in range(len(w)):\n",
    "                result[i][j] += X[i][k] * w[k][j]\n",
    "            result[i][j] += b\n",
    "\n",
    "    f = np.asarray(result, dtype=np.float64)\n",
    "    return f\n",
    "\n",
    "\n",
    "# compute gradients with respect to w and b\n",
    "# YOU NEEED TO IMPLEMENT THIS\n",
    "signed = np.vectorize(lambda t: 1. if  t > 0. else 0.)\n",
    "\n",
    "def _inverse_multiple(X,y):\n",
    "    result = np.full((len(X),len(X[0])), 0).tolist()\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        for j in range(len(X[i])):\n",
    "            result[i][j] = X[i][j] * y[j][0]\n",
    "\n",
    "    f = np.asarray(result)\n",
    "    return f\n",
    "\n",
    "def _get_gradients(f, X, y, w, b, lam):\n",
    "    nobs = len(X)\n",
    "    yf = y * f\n",
    "    t = signed(1. - yf)\n",
    "    ty = t * y\n",
    "    \n",
    "    gb = np.sum(ty) / nobs\n",
    "    gw = np.sum(_inverse_multiple(X, ty), axis=0) / nobs\n",
    "    gw += lam * w\n",
    "    \n",
    "    return gw, gb\n",
    "\n",
    "\n",
    "# fit an SVM using gradient descent\n",
    "# X: matrix of feature values\n",
    "# y: labels (-1 or 1)\n",
    "# lam: penalty parameter lambda\n",
    "# n_iter: numer of iterations\n",
    "# eta: learning rate\n",
    "def fit_svm(X, y, lam, n_iter=100, eta=.4):\n",
    "    nexamples, nfeatures = X.shape\n",
    "    \n",
    "    w, b = _initialize_parameters(nfeatures)\n",
    "    \n",
    "    for k in range(n_iter):\n",
    "        f = _get_signed_distances(X, w, b)\n",
    "        \n",
    "        # print information and \n",
    "        # update the learning rate\n",
    "        if k % 10 == 0:\n",
    "            obj = _get_objective(f, y, w, lam)\n",
    "            eta = eta / 2.0\n",
    "            print(\"it: %d, obj %.2f\" % (k, obj))\n",
    "        \n",
    "        gw, gb = _get_gradients(f, X, y, w, b, lam)\n",
    "        w = w - eta * gw\n",
    "        b = b - eta * gb\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = fit_svm(train_X, train_y, 1.0, n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47.]\n",
      " [64.]\n",
      " [78.]]\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "X = np.array([[1, 3,2,6],\n",
    "                   [4, 0,5,7],\n",
    "                   [2, 1,6,8]])\n",
    "\n",
    "Y = np.array([[1],[5],[9],[2]])\n",
    "result = _get_signed_distances(X,Y,1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 15]\n",
      " [ 4  0]\n",
      " [ 2  5]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 3],\n",
    "                   [4, 0],\n",
    "                   [2, 1]])\n",
    "\n",
    "y = np.array([[1],[5]])\n",
    "\n",
    "result = _inverse_multiple(X,y)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
